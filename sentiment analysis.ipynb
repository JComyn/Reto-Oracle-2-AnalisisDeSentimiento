{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the csv files\n",
    "train_df = pd.read_csv(r\"train.csv\")\n",
    "test_df = pd.read_csv(r\"test.csv\")\n",
    "\n",
    "train_data = train_df['text'].tolist()\n",
    "train_labels = train_df['label'].tolist() # 0 = negative, 1 = positive\n",
    "\n",
    "test_data = test_df['text'].tolist()\n",
    "\n",
    "#print(len(train_data))\n",
    "#print(len(train_labels))\n",
    "#print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
       "array([b'i really do recommend this to anyone in need of a new player',\n",
       "       b'very good every day camera fits nicely in the pocket of my jeans and takes quality photos',\n",
       "       b'but , dollar for dollar , this dvd player is probably the best out there',\n",
       "       b\"i got this phone yesterday and didn ' t find any problems with it yet\",\n",
       "       b'1 ) price gb of storage',\n",
       "       b'one cabinet shop has been using one regularly in a router table for 11 years without a problem',\n",
       "       b'i will say that the os that the phone runs does have a few issues',\n",
       "       b'this model appears to be especially good',\n",
       "       b\"i find that it is stable in my hands and its ' weight actually contributes to that stability\",\n",
       "       b'the catch is that , while it plays movies just fine , it has refused to read second discs with the movie extras on them on the two occasions when i tried to do that'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_dataset.batch(10)))\n",
    "train_examples_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 50), dtype=float32, numpy=\n",
       "array([[ 0.19757974, -0.0186452 , -0.08237637,  0.3675822 , -0.04530753,\n",
       "         0.20239483,  0.08419446,  0.04277235, -0.1744885 ,  0.42727035,\n",
       "        -0.05284091,  0.13069119, -0.13883512, -0.11575663,  0.00941333,\n",
       "         0.05545775, -0.10175671,  0.08229759,  0.10384491, -0.21822135,\n",
       "        -0.02120312,  0.08206433,  0.15686706, -0.02654655, -0.14630347,\n",
       "         0.19497168, -0.70362455,  0.06724163, -0.04180326, -0.1357327 ,\n",
       "        -0.00549761,  0.20079505,  0.07402345, -0.13822946, -0.12910356,\n",
       "        -0.06940438,  0.17769675, -0.22498287, -0.02418699, -0.32836828,\n",
       "         0.1543761 ,  0.08618873, -0.11317721,  0.16600314, -0.06893973,\n",
       "        -0.21479215, -0.02556792, -0.20228562,  0.12176652,  0.2922582 ],\n",
       "       [ 0.13493924,  0.08447167,  0.10208606,  0.33875805, -0.39271924,\n",
       "        -0.11495312,  0.2911141 , -0.12646888, -0.21781461,  0.14495888,\n",
       "         0.24699204,  0.21629849, -0.07006254,  0.11604493, -0.06587031,\n",
       "        -0.39131925,  0.10963789, -0.07245144, -0.05174111, -0.33384898,\n",
       "        -0.3718696 , -0.00561796,  0.08974221,  0.06901132, -0.0448915 ,\n",
       "         0.02646273, -0.40602404,  0.0093478 ,  0.24397677,  0.09384149,\n",
       "         0.06180502,  0.31506413,  0.05874644, -0.15963884, -0.0761799 ,\n",
       "        -0.05733013,  0.23758474,  0.11051102,  0.06912752, -0.45962593,\n",
       "         0.17837787, -0.02146578, -0.12267721,  0.2645883 ,  0.08606868,\n",
       "        -0.17057458, -0.2262558 , -0.15639126,  0.20506844,  0.14201869],\n",
       "       [ 0.17692713,  0.08408133, -0.13763921,  0.11433976,  0.01975585,\n",
       "        -0.22512865,  0.01604079,  0.03038905, -0.3260738 ,  0.19271407,\n",
       "         0.18433294,  0.10843889,  0.01097899, -0.01387053, -0.00082416,\n",
       "         0.07495803, -0.3143453 ,  0.1579425 ,  0.17349185, -0.40114397,\n",
       "        -0.18717144, -0.07352237,  0.5719334 ,  0.20893928, -0.19663918,\n",
       "         0.23981066, -0.35979056,  0.17667486,  0.10137713, -0.0615684 ,\n",
       "        -0.02007254, -0.1491484 ,  0.10818045, -0.12883574, -0.09312247,\n",
       "        -0.01899156,  0.07184548, -0.24156664,  0.21429989, -0.29592672,\n",
       "        -0.29290825,  0.13555665, -0.15143459,  0.02027303,  0.04256035,\n",
       "        -0.22148444, -0.06891961, -0.20568419, -0.01340047,  0.2796641 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\comyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\comyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3264      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,196,361\n",
      "Trainable params: 48,196,169\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1, kernel_regularizer=l2(0.001)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=(tf.metrics.BinaryAccuracy(threshold=0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "61/61 [==============================] - 103s 2s/step - loss: 0.7768 - binary_accuracy: 0.6333\n",
      "Epoch 2/5\n",
      "61/61 [==============================] - 92s 2s/step - loss: 0.5936 - binary_accuracy: 0.7699\n",
      "Epoch 3/5\n",
      "61/61 [==============================] - 100s 2s/step - loss: 0.4722 - binary_accuracy: 0.8362\n",
      "Epoch 4/5\n",
      "61/61 [==============================] - 104s 2s/step - loss: 0.3893 - binary_accuracy: 0.8859\n",
      "Epoch 5/5\n",
      "61/61 [==============================] - 88s 1s/step - loss: 0.3180 - binary_accuracy: 0.9121\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset.shuffle(500).batch(50),\n",
    "                    epochs=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Activation('sigmoid')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 7s 255ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7498362 ],\n",
       "       [0.81120735],\n",
       "       [0.9272246 ],\n",
       "       [0.88177866],\n",
       "       [0.91660416],\n",
       "       [0.37024584],\n",
       "       [0.5670207 ],\n",
       "       [0.8485461 ],\n",
       "       [0.6456509 ],\n",
       "       [0.8689728 ],\n",
       "       [0.7103296 ],\n",
       "       [0.6784979 ],\n",
       "       [0.76707596],\n",
       "       [0.96740067],\n",
       "       [0.8067341 ],\n",
       "       [0.89576834],\n",
       "       [0.3853816 ],\n",
       "       [0.62183017],\n",
       "       [0.8497489 ],\n",
       "       [0.5206521 ],\n",
       "       [0.9298378 ],\n",
       "       [0.92433745],\n",
       "       [0.863692  ],\n",
       "       [0.87969023],\n",
       "       [0.94096446],\n",
       "       [0.9445191 ],\n",
       "       [0.952483  ],\n",
       "       [0.804348  ],\n",
       "       [0.9535071 ],\n",
       "       [0.94792366],\n",
       "       [0.85923904],\n",
       "       [0.3319982 ],\n",
       "       [0.8467337 ],\n",
       "       [0.95850015],\n",
       "       [0.8270234 ],\n",
       "       [0.42124242],\n",
       "       [0.90024835],\n",
       "       [0.94142175],\n",
       "       [0.6938723 ],\n",
       "       [0.63876617],\n",
       "       [0.6163538 ],\n",
       "       [0.12690559],\n",
       "       [0.6392217 ],\n",
       "       [0.49973494],\n",
       "       [0.6346485 ],\n",
       "       [0.96791095],\n",
       "       [0.86841446],\n",
       "       [0.88438094],\n",
       "       [0.6857827 ],\n",
       "       [0.77632374],\n",
       "       [0.73150563],\n",
       "       [0.17629023],\n",
       "       [0.89817864],\n",
       "       [0.79688877],\n",
       "       [0.64993924],\n",
       "       [0.70159084],\n",
       "       [0.7037537 ],\n",
       "       [0.45247594],\n",
       "       [0.97323287],\n",
       "       [0.799536  ],\n",
       "       [0.7211865 ],\n",
       "       [0.6450349 ],\n",
       "       [0.609824  ],\n",
       "       [0.9405853 ],\n",
       "       [0.27452743],\n",
       "       [0.83326715],\n",
       "       [0.90658635],\n",
       "       [0.8736872 ],\n",
       "       [0.9552326 ],\n",
       "       [0.65771466],\n",
       "       [0.9327425 ],\n",
       "       [0.9076932 ],\n",
       "       [0.9034028 ],\n",
       "       [0.62152386],\n",
       "       [0.93180037],\n",
       "       [0.89034075],\n",
       "       [0.9294863 ],\n",
       "       [0.07884693],\n",
       "       [0.4633683 ],\n",
       "       [0.930705  ],\n",
       "       [0.9506181 ],\n",
       "       [0.65543264],\n",
       "       [0.6675959 ],\n",
       "       [0.76288575],\n",
       "       [0.8353656 ],\n",
       "       [0.96952605],\n",
       "       [0.53477657],\n",
       "       [0.96225697],\n",
       "       [0.9778205 ],\n",
       "       [0.9443531 ],\n",
       "       [0.9043429 ],\n",
       "       [0.88752437],\n",
       "       [0.91393876],\n",
       "       [0.838124  ],\n",
       "       [0.908326  ],\n",
       "       [0.66305554],\n",
       "       [0.9702121 ],\n",
       "       [0.7491426 ],\n",
       "       [0.13094372],\n",
       "       [0.85231227],\n",
       "       [0.95522344],\n",
       "       [0.51599836],\n",
       "       [0.90684026],\n",
       "       [0.92475176],\n",
       "       [0.7641993 ],\n",
       "       [0.7421943 ],\n",
       "       [0.65525377],\n",
       "       [0.60197353],\n",
       "       [0.9519842 ],\n",
       "       [0.93534815],\n",
       "       [0.7949054 ],\n",
       "       [0.27320024],\n",
       "       [0.52283245],\n",
       "       [0.92436016],\n",
       "       [0.21908368],\n",
       "       [0.76926315],\n",
       "       [0.6937893 ],\n",
       "       [0.89873296],\n",
       "       [0.98499775],\n",
       "       [0.942016  ],\n",
       "       [0.3596302 ],\n",
       "       [0.8650816 ],\n",
       "       [0.9120916 ],\n",
       "       [0.9305435 ],\n",
       "       [0.8056332 ],\n",
       "       [0.22560036],\n",
       "       [0.7961116 ],\n",
       "       [0.9081949 ],\n",
       "       [0.8079236 ],\n",
       "       [0.9628407 ],\n",
       "       [0.9269644 ],\n",
       "       [0.4757342 ],\n",
       "       [0.42777225],\n",
       "       [0.9178944 ],\n",
       "       [0.84943944],\n",
       "       [0.6731205 ],\n",
       "       [0.74265397],\n",
       "       [0.92365056],\n",
       "       [0.9698792 ],\n",
       "       [0.9542942 ],\n",
       "       [0.97397494],\n",
       "       [0.6019882 ],\n",
       "       [0.96454245],\n",
       "       [0.5423757 ],\n",
       "       [0.87235236],\n",
       "       [0.9570435 ],\n",
       "       [0.49873212],\n",
       "       [0.9104335 ],\n",
       "       [0.8596666 ],\n",
       "       [0.92885256],\n",
       "       [0.70160615],\n",
       "       [0.9492188 ],\n",
       "       [0.95628184],\n",
       "       [0.700568  ],\n",
       "       [0.7971964 ],\n",
       "       [0.93963015],\n",
       "       [0.9483199 ],\n",
       "       [0.84369993],\n",
       "       [0.9090703 ],\n",
       "       [0.86772734],\n",
       "       [0.6841708 ],\n",
       "       [0.36682063],\n",
       "       [0.8683153 ],\n",
       "       [0.23366494],\n",
       "       [0.566284  ],\n",
       "       [0.75230616],\n",
       "       [0.79443467],\n",
       "       [0.705778  ],\n",
       "       [0.49885884],\n",
       "       [0.8221097 ],\n",
       "       [0.9202116 ],\n",
       "       [0.9531154 ],\n",
       "       [0.8202665 ],\n",
       "       [0.83386743],\n",
       "       [0.9357125 ],\n",
       "       [0.6609171 ],\n",
       "       [0.675698  ],\n",
       "       [0.8996718 ],\n",
       "       [0.9690025 ],\n",
       "       [0.91816854],\n",
       "       [0.9478231 ],\n",
       "       [0.96624726],\n",
       "       [0.8560561 ],\n",
       "       [0.5375503 ],\n",
       "       [0.793665  ],\n",
       "       [0.8240824 ],\n",
       "       [0.8002344 ],\n",
       "       [0.65697867],\n",
       "       [0.7043022 ],\n",
       "       [0.7847264 ],\n",
       "       [0.9365084 ],\n",
       "       [0.623828  ],\n",
       "       [0.28238586],\n",
       "       [0.91908246],\n",
       "       [0.89256686],\n",
       "       [0.9045681 ],\n",
       "       [0.84460723],\n",
       "       [0.8523557 ],\n",
       "       [0.9363805 ],\n",
       "       [0.98121434],\n",
       "       [0.74939704],\n",
       "       [0.49583206],\n",
       "       [0.876997  ],\n",
       "       [0.91974247],\n",
       "       [0.79405993],\n",
       "       [0.92532283],\n",
       "       [0.3768036 ],\n",
       "       [0.64301485],\n",
       "       [0.5883463 ],\n",
       "       [0.843758  ],\n",
       "       [0.9100821 ],\n",
       "       [0.2873133 ],\n",
       "       [0.9543036 ],\n",
       "       [0.7413615 ],\n",
       "       [0.886899  ],\n",
       "       [0.7614962 ],\n",
       "       [0.87950295],\n",
       "       [0.9520953 ],\n",
       "       [0.8310025 ],\n",
       "       [0.8407515 ],\n",
       "       [0.43547335],\n",
       "       [0.6818918 ],\n",
       "       [0.74338317],\n",
       "       [0.90981233],\n",
       "       [0.8813386 ],\n",
       "       [0.79605305],\n",
       "       [0.8858481 ],\n",
       "       [0.53517216],\n",
       "       [0.9605476 ],\n",
       "       [0.86158305],\n",
       "       [0.41427705],\n",
       "       [0.9247106 ],\n",
       "       [0.9005526 ],\n",
       "       [0.8447533 ],\n",
       "       [0.66367984],\n",
       "       [0.6123731 ],\n",
       "       [0.7223897 ],\n",
       "       [0.9452149 ],\n",
       "       [0.8890892 ],\n",
       "       [0.9636027 ],\n",
       "       [0.95473367],\n",
       "       [0.9057157 ],\n",
       "       [0.9155673 ],\n",
       "       [0.39496496],\n",
       "       [0.7870217 ],\n",
       "       [0.5245259 ],\n",
       "       [0.86995757],\n",
       "       [0.91628116],\n",
       "       [0.9642749 ],\n",
       "       [0.90541273],\n",
       "       [0.8247307 ],\n",
       "       [0.88203233],\n",
       "       [0.9031367 ],\n",
       "       [0.4643866 ],\n",
       "       [0.9785288 ],\n",
       "       [0.70776874],\n",
       "       [0.9095942 ],\n",
       "       [0.44319123],\n",
       "       [0.86464703],\n",
       "       [0.8477696 ],\n",
       "       [0.77707356],\n",
       "       [0.90276736],\n",
       "       [0.57840776],\n",
       "       [0.9268768 ],\n",
       "       [0.578417  ],\n",
       "       [0.7349767 ],\n",
       "       [0.9555643 ],\n",
       "       [0.92352104],\n",
       "       [0.92032236],\n",
       "       [0.45088238],\n",
       "       [0.89347106],\n",
       "       [0.88631785],\n",
       "       [0.8905152 ],\n",
       "       [0.33173117],\n",
       "       [0.81568307],\n",
       "       [0.73473686],\n",
       "       [0.334667  ],\n",
       "       [0.93165505],\n",
       "       [0.88080734],\n",
       "       [0.8591819 ],\n",
       "       [0.8661093 ],\n",
       "       [0.92348576],\n",
       "       [0.3515599 ],\n",
       "       [0.266651  ],\n",
       "       [0.7143567 ],\n",
       "       [0.6671325 ],\n",
       "       [0.8149426 ],\n",
       "       [0.7902195 ],\n",
       "       [0.7945295 ],\n",
       "       [0.9491857 ],\n",
       "       [0.63531595],\n",
       "       [0.96050656],\n",
       "       [0.9285341 ],\n",
       "       [0.80531067],\n",
       "       [0.9357265 ],\n",
       "       [0.79955477],\n",
       "       [0.9257303 ],\n",
       "       [0.56493664],\n",
       "       [0.86676717],\n",
       "       [0.9647467 ],\n",
       "       [0.8960577 ],\n",
       "       [0.7397244 ],\n",
       "       [0.82451934],\n",
       "       [0.35957795],\n",
       "       [0.700022  ],\n",
       "       [0.82981247],\n",
       "       [0.76062554],\n",
       "       [0.6180456 ],\n",
       "       [0.86710817],\n",
       "       [0.7309778 ],\n",
       "       [0.87982094],\n",
       "       [0.91111887],\n",
       "       [0.89091426],\n",
       "       [0.9772248 ],\n",
       "       [0.93545485],\n",
       "       [0.80024767],\n",
       "       [0.95037615],\n",
       "       [0.82878125],\n",
       "       [0.8657533 ],\n",
       "       [0.9811968 ],\n",
       "       [0.9149973 ],\n",
       "       [0.335079  ],\n",
       "       [0.96186554],\n",
       "       [0.37536696],\n",
       "       [0.7665602 ],\n",
       "       [0.7645544 ],\n",
       "       [0.76898086],\n",
       "       [0.94649744],\n",
       "       [0.9348245 ],\n",
       "       [0.87525856],\n",
       "       [0.82783985],\n",
       "       [0.95681494],\n",
       "       [0.9656024 ],\n",
       "       [0.90315366],\n",
       "       [0.82060933],\n",
       "       [0.78895706],\n",
       "       [0.5679317 ],\n",
       "       [0.9106529 ],\n",
       "       [0.8094208 ],\n",
       "       [0.53618354],\n",
       "       [0.96446425],\n",
       "       [0.8843285 ],\n",
       "       [0.84382814],\n",
       "       [0.836264  ],\n",
       "       [0.80424416],\n",
       "       [0.19437236],\n",
       "       [0.8660713 ],\n",
       "       [0.6123043 ],\n",
       "       [0.90024126],\n",
       "       [0.96409386],\n",
       "       [0.88904697],\n",
       "       [0.8564991 ],\n",
       "       [0.9158715 ],\n",
       "       [0.84096485],\n",
       "       [0.7657777 ],\n",
       "       [0.7915716 ],\n",
       "       [0.5413181 ],\n",
       "       [0.8811733 ],\n",
       "       [0.7395258 ],\n",
       "       [0.6965833 ],\n",
       "       [0.5595927 ],\n",
       "       [0.834125  ],\n",
       "       [0.9545106 ],\n",
       "       [0.9007654 ],\n",
       "       [0.92314583],\n",
       "       [0.9407144 ],\n",
       "       [0.8627797 ],\n",
       "       [0.81309175],\n",
       "       [0.94057554],\n",
       "       [0.40758932],\n",
       "       [0.9063076 ],\n",
       "       [0.97165704],\n",
       "       [0.8704247 ],\n",
       "       [0.9576731 ],\n",
       "       [0.96652806],\n",
       "       [0.9186275 ],\n",
       "       [0.73346895],\n",
       "       [0.86778104],\n",
       "       [0.15063216],\n",
       "       [0.9722762 ],\n",
       "       [0.9525535 ],\n",
       "       [0.9296723 ],\n",
       "       [0.23763168],\n",
       "       [0.6379348 ],\n",
       "       [0.42629644],\n",
       "       [0.93962294],\n",
       "       [0.956723  ],\n",
       "       [0.92089874],\n",
       "       [0.8670153 ],\n",
       "       [0.6917811 ],\n",
       "       [0.9555846 ],\n",
       "       [0.85025036],\n",
       "       [0.91596895],\n",
       "       [0.9062548 ],\n",
       "       [0.958914  ],\n",
       "       [0.80088794],\n",
       "       [0.8427724 ],\n",
       "       [0.91250795],\n",
       "       [0.65218675],\n",
       "       [0.66774756],\n",
       "       [0.9083245 ],\n",
       "       [0.6727693 ],\n",
       "       [0.9030078 ],\n",
       "       [0.37391034],\n",
       "       [0.8328643 ],\n",
       "       [0.8795657 ],\n",
       "       [0.9007882 ],\n",
       "       [0.9639605 ],\n",
       "       [0.93692416],\n",
       "       [0.8104183 ],\n",
       "       [0.8657704 ],\n",
       "       [0.78026485],\n",
       "       [0.8994281 ],\n",
       "       [0.73499036],\n",
       "       [0.93509674],\n",
       "       [0.81570584],\n",
       "       [0.9212616 ],\n",
       "       [0.7790449 ],\n",
       "       [0.8986821 ],\n",
       "       [0.9535174 ],\n",
       "       [0.90942705],\n",
       "       [0.9334191 ],\n",
       "       [0.9061052 ],\n",
       "       [0.83739537],\n",
       "       [0.88611466],\n",
       "       [0.33122355],\n",
       "       [0.92663044],\n",
       "       [0.6087271 ],\n",
       "       [0.33688697],\n",
       "       [0.8711667 ],\n",
       "       [0.82042813],\n",
       "       [0.9745066 ],\n",
       "       [0.9004255 ],\n",
       "       [0.81786567],\n",
       "       [0.9356889 ],\n",
       "       [0.9145218 ],\n",
       "       [0.506731  ],\n",
       "       [0.9633656 ],\n",
       "       [0.50180066],\n",
       "       [0.7486418 ],\n",
       "       [0.86631197],\n",
       "       [0.51316136],\n",
       "       [0.95274675],\n",
       "       [0.91481555],\n",
       "       [0.98246545],\n",
       "       [0.8846033 ],\n",
       "       [0.49613374],\n",
       "       [0.8603349 ],\n",
       "       [0.9695379 ],\n",
       "       [0.9276426 ],\n",
       "       [0.84141445],\n",
       "       [0.89543986],\n",
       "       [0.33807608],\n",
       "       [0.62922865],\n",
       "       [0.9799761 ],\n",
       "       [0.94147587],\n",
       "       [0.6189051 ],\n",
       "       [0.8959638 ],\n",
       "       [0.97179574],\n",
       "       [0.9327201 ],\n",
       "       [0.9299742 ],\n",
       "       [0.696931  ],\n",
       "       [0.9522955 ],\n",
       "       [0.76211965],\n",
       "       [0.9306925 ],\n",
       "       [0.87545234],\n",
       "       [0.75018454],\n",
       "       [0.9664123 ],\n",
       "       [0.93931514],\n",
       "       [0.91725093],\n",
       "       [0.8230319 ],\n",
       "       [0.979967  ],\n",
       "       [0.85413593],\n",
       "       [0.9367415 ],\n",
       "       [0.17588723],\n",
       "       [0.8272963 ],\n",
       "       [0.8888446 ],\n",
       "       [0.8698384 ],\n",
       "       [0.96503085],\n",
       "       [0.93562305],\n",
       "       [0.95389795],\n",
       "       [0.92701656],\n",
       "       [0.45811868],\n",
       "       [0.7304033 ],\n",
       "       [0.9082711 ],\n",
       "       [0.9533273 ],\n",
       "       [0.22037365],\n",
       "       [0.8803536 ],\n",
       "       [0.62855923],\n",
       "       [0.78636414],\n",
       "       [0.77863866],\n",
       "       [0.9382418 ],\n",
       "       [0.94990885],\n",
       "       [0.8211917 ],\n",
       "       [0.95964026],\n",
       "       [0.30256206],\n",
       "       [0.91829985],\n",
       "       [0.96340066],\n",
       "       [0.9443696 ],\n",
       "       [0.06828784],\n",
       "       [0.9342622 ],\n",
       "       [0.8437527 ],\n",
       "       [0.9343598 ],\n",
       "       [0.8941727 ],\n",
       "       [0.39929575],\n",
       "       [0.90471655],\n",
       "       [0.82373554],\n",
       "       [0.718691  ],\n",
       "       [0.7176416 ],\n",
       "       [0.681383  ],\n",
       "       [0.9165099 ],\n",
       "       [0.820123  ],\n",
       "       [0.9334634 ],\n",
       "       [0.7675341 ],\n",
       "       [0.91326773],\n",
       "       [0.94062275],\n",
       "       [0.5227823 ],\n",
       "       [0.85923994],\n",
       "       [0.95527446],\n",
       "       [0.97172344],\n",
       "       [0.83017606],\n",
       "       [0.83624476],\n",
       "       [0.607658  ],\n",
       "       [0.89961076],\n",
       "       [0.7730579 ],\n",
       "       [0.7412846 ],\n",
       "       [0.9059321 ],\n",
       "       [0.7567549 ],\n",
       "       [0.8601635 ],\n",
       "       [0.9056098 ],\n",
       "       [0.9260363 ],\n",
       "       [0.956779  ],\n",
       "       [0.8722083 ],\n",
       "       [0.7939638 ],\n",
       "       [0.7073283 ],\n",
       "       [0.8095388 ],\n",
       "       [0.87160975],\n",
       "       [0.96309465],\n",
       "       [0.9500709 ],\n",
       "       [0.8753039 ],\n",
       "       [0.968666  ],\n",
       "       [0.91950244],\n",
       "       [0.9652269 ],\n",
       "       [0.95607716],\n",
       "       [0.6366889 ],\n",
       "       [0.8622543 ],\n",
       "       [0.43087038],\n",
       "       [0.9697656 ],\n",
       "       [0.75238323],\n",
       "       [0.87962955],\n",
       "       [0.9239329 ],\n",
       "       [0.8290417 ],\n",
       "       [0.9678608 ],\n",
       "       [0.9373201 ],\n",
       "       [0.9495586 ],\n",
       "       [0.40233907],\n",
       "       [0.94217026],\n",
       "       [0.9696267 ],\n",
       "       [0.38599285],\n",
       "       [0.95016867],\n",
       "       [0.49498534],\n",
       "       [0.92957574],\n",
       "       [0.84377   ],\n",
       "       [0.77546996],\n",
       "       [0.8851309 ],\n",
       "       [0.9583247 ],\n",
       "       [0.96843266],\n",
       "       [0.60699946],\n",
       "       [0.9429307 ],\n",
       "       [0.84509444],\n",
       "       [0.9409078 ],\n",
       "       [0.66824824],\n",
       "       [0.95693976],\n",
       "       [0.42011946],\n",
       "       [0.9032847 ],\n",
       "       [0.93641335],\n",
       "       [0.90465015],\n",
       "       [0.9156946 ],\n",
       "       [0.9548648 ],\n",
       "       [0.5388904 ],\n",
       "       [0.92370945],\n",
       "       [0.8997728 ],\n",
       "       [0.5840654 ],\n",
       "       [0.7678125 ],\n",
       "       [0.94488704],\n",
       "       [0.6730409 ],\n",
       "       [0.6210935 ],\n",
       "       [0.5562006 ],\n",
       "       [0.40108228],\n",
       "       [0.78122544],\n",
       "       [0.9591878 ],\n",
       "       [0.87566316],\n",
       "       [0.7259942 ],\n",
       "       [0.82359976],\n",
       "       [0.8341703 ],\n",
       "       [0.92247623],\n",
       "       [0.47645286],\n",
       "       [0.81069237],\n",
       "       [0.77167225],\n",
       "       [0.8589646 ],\n",
       "       [0.5691449 ],\n",
       "       [0.80139035],\n",
       "       [0.85781145],\n",
       "       [0.68573976],\n",
       "       [0.93619335],\n",
       "       [0.40752816],\n",
       "       [0.7838858 ],\n",
       "       [0.9755249 ],\n",
       "       [0.8661438 ],\n",
       "       [0.8177988 ],\n",
       "       [0.94552404],\n",
       "       [0.53456086],\n",
       "       [0.8449712 ],\n",
       "       [0.9077979 ],\n",
       "       [0.940191  ],\n",
       "       [0.88055843],\n",
       "       [0.79621965],\n",
       "       [0.8340495 ],\n",
       "       [0.93995655],\n",
       "       [0.89620167],\n",
       "       [0.9141255 ],\n",
       "       [0.9546617 ],\n",
       "       [0.8275486 ],\n",
       "       [0.85778236],\n",
       "       [0.9476995 ],\n",
       "       [0.84353846],\n",
       "       [0.85311145],\n",
       "       [0.8286696 ],\n",
       "       [0.93970454],\n",
       "       [0.8830236 ],\n",
       "       [0.3961622 ],\n",
       "       [0.95292675],\n",
       "       [0.4269542 ],\n",
       "       [0.50428563],\n",
       "       [0.90682346],\n",
       "       [0.560034  ],\n",
       "       [0.8642813 ],\n",
       "       [0.4599146 ],\n",
       "       [0.96730465],\n",
       "       [0.72820467],\n",
       "       [0.7812649 ],\n",
       "       [0.95784116],\n",
       "       [0.90826505],\n",
       "       [0.8664175 ],\n",
       "       [0.89102465],\n",
       "       [0.94373035],\n",
       "       [0.5618402 ],\n",
       "       [0.8926103 ],\n",
       "       [0.9773996 ],\n",
       "       [0.9673971 ],\n",
       "       [0.7412492 ],\n",
       "       [0.59104794],\n",
       "       [0.92805547],\n",
       "       [0.907329  ],\n",
       "       [0.8878363 ],\n",
       "       [0.88638663],\n",
       "       [0.7749194 ],\n",
       "       [0.9122286 ],\n",
       "       [0.97736573],\n",
       "       [0.9413422 ],\n",
       "       [0.8596097 ],\n",
       "       [0.19527782],\n",
       "       [0.8185696 ],\n",
       "       [0.86008435],\n",
       "       [0.93532467],\n",
       "       [0.9803287 ],\n",
       "       [0.78654975],\n",
       "       [0.74886733],\n",
       "       [0.8190928 ],\n",
       "       [0.9736284 ],\n",
       "       [0.85371655],\n",
       "       [0.9324246 ],\n",
       "       [0.93762255],\n",
       "       [0.9762564 ],\n",
       "       [0.9370564 ],\n",
       "       [0.88965434],\n",
       "       [0.942243  ],\n",
       "       [0.34261465],\n",
       "       [0.93186694],\n",
       "       [0.9220089 ],\n",
       "       [0.8935    ],\n",
       "       [0.95803285],\n",
       "       [0.7961908 ],\n",
       "       [0.9568096 ],\n",
       "       [0.94460595],\n",
       "       [0.5733962 ],\n",
       "       [0.57738936],\n",
       "       [0.93657845],\n",
       "       [0.89147085],\n",
       "       [0.90110666],\n",
       "       [0.85164493],\n",
       "       [0.9323497 ],\n",
       "       [0.37545732],\n",
       "       [0.54179794],\n",
       "       [0.82992446],\n",
       "       [0.6780524 ],\n",
       "       [0.790637  ],\n",
       "       [0.5848999 ],\n",
       "       [0.75422055],\n",
       "       [0.7965601 ],\n",
       "       [0.82204807],\n",
       "       [0.85009557],\n",
       "       [0.90535754],\n",
       "       [0.7769455 ],\n",
       "       [0.95433664],\n",
       "       [0.7869772 ],\n",
       "       [0.9535059 ],\n",
       "       [0.72117597],\n",
       "       [0.42509085],\n",
       "       [0.758091  ],\n",
       "       [0.85158646],\n",
       "       [0.4960457 ],\n",
       "       [0.70971406],\n",
       "       [0.943872  ],\n",
       "       [0.9424198 ],\n",
       "       [0.35489145],\n",
       "       [0.9060283 ],\n",
       "       [0.73103005],\n",
       "       [0.46506622],\n",
       "       [0.79196465],\n",
       "       [0.5263518 ],\n",
       "       [0.9415366 ],\n",
       "       [0.2908805 ],\n",
       "       [0.5037854 ],\n",
       "       [0.9693974 ],\n",
       "       [0.96510196],\n",
       "       [0.8831071 ],\n",
       "       [0.92383194],\n",
       "       [0.7581691 ],\n",
       "       [0.48888972],\n",
       "       [0.70587814],\n",
       "       [0.89948213],\n",
       "       [0.88611156],\n",
       "       [0.6878131 ],\n",
       "       [0.32543528],\n",
       "       [0.88802105],\n",
       "       [0.95972896],\n",
       "       [0.8677426 ],\n",
       "       [0.48220393],\n",
       "       [0.9500801 ],\n",
       "       [0.90688825],\n",
       "       [0.920576  ],\n",
       "       [0.9364731 ],\n",
       "       [0.564564  ],\n",
       "       [0.9774244 ],\n",
       "       [0.4084317 ],\n",
       "       [0.93203855],\n",
       "       [0.9291237 ],\n",
       "       [0.90833193],\n",
       "       [0.77417797],\n",
       "       [0.33711517],\n",
       "       [0.6521336 ],\n",
       "       [0.8430489 ],\n",
       "       [0.77211285]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = probability_model.predict(test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON file with predictions\n",
    "\n",
    "# Create a dictionary with the predictions\n",
    "predictions_dict = {}\n",
    "for i in range(0, len(predictions)):\n",
    "    predictions_dict[str(i)] = (int)(np.round(predictions[i]))\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open('predictions4.json', 'w') as f:\n",
    "    json.dump(predictions_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
